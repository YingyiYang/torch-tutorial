{
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language": "lua",
  "language_info": {
   "name": "lua",
   "version": "5.1"
  },
  "name": "",
  "signature": "sha256:93ef770056bb4b22755345032e30e7794fca98adbb481a739ff0ddc56afc8dc7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "# MNIST Classification\n",
      "\n",
      "by learning how to classify the handwritten digits found in the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset!\n",
      "\n",
      "\n",
      "In Torch, MNIST is conveniently available from the `mnist` package which we will import using"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnist = require 'mnist'\n",
      "print(mnist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "{\n",
        "  testdataset : function: 0x0a0022e0\n",
        "  traindataset : function: 0x0a002268\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functions that were imported can be called to yield the images and labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainData = mnist.traindataset()\n",
      "print(trainData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{\n",
        "  data : ByteTensor - size: 60000x28x28\n",
        "  size : 60000\n",
        "  label : ByteTensor - size: 60000\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which look like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images = {}\n",
      "labels = {}\n",
      "for i=1,5 do\n",
      "    r = torch.random(trainData.size)\n",
      "    images[i] = trainData.data[r]\n",
      "    labels[i] = trainData.label[r]\n",
      "end\n",
      "--itorch.image(images)\n",
      "for i=1,5 do io.write(labels[i]..' ') end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "6 8 2 7 1 "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems reasonable. Let's see if our computers agree! \n",
      "\n",
      "## DataLoader\n",
      "\n",
      "For the remainder of this workshop, you'll be getting your hands dirty by first filling in a very basic skeleton of the data loader and then writing and tuning several models to get the best performance on MNIST!\n",
      "\n",
      "### One-sample, two-sample, $n$-sample, batch!\n",
      "\n",
      "A neural network is like any other function: it takes some inputs (data) and produces some outputs (predictions). In this section, we'll work with the code found in [`mnist/dataloder.lua`](../edit/mnist/dataloader.lua).\n",
      "\n",
      "Let's start with a quick tour:\n",
      "\n",
      "The first new piece of machinery is on line 4: \n",
      "\n",
      "```lua\n",
      "local DataLoader = torch.class('DataLoader')\n",
      "```\n",
      "\n",
      "If you hearken back to the Intro to Lua segment, you'll recall that Lua tables can be used like classes in standard object-oriented programming. Torch makes this easy by handling all of the boilerplate in [torch.class](https://github.com/torch/torch7/blob/master/doc/utility.md#torch.class) so that all you need to do is implement the methods you care about. In this case, we will want\n",
      "\n",
      "* `__init` (a default method) which is analagous to `__init__` in Python,\n",
      "* `run` (a custom method) which will return an iterator over our dataset, and\n",
      "* `size` (a custom method) which will return the size of the training or validation set\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dofile('mnist/dataloader.lua')\n",
      "local loader = DataLoader{batchSize=4}\n",
      "iter = loader:run('train')\n",
      "local n,data = iter()\n",
      "print(data.labels)\n",
      "--itorch.image(data.images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "  2\n",
        "  5\n",
        " 10\n",
        "  4\n",
        "[torch.ByteTensor of size 4]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "## `nn`: For (Almost) All of Your Neural Network Needs\n",
      "\n",
      "Another of the many reasons why Torch really shines (glows?) is that it has a comprehensive set of \"modules\" that you can string together like lego blocks to produce even highly complicated networks. This is largely in part due to the programming abstractions it uses, which we shall soon see.\n",
      "\n",
      "Like `mnist` we can import the `nn` package using"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "require 'nn';"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### The Real Learning Modules\n",
      "\n",
      "All of the modules in `nn` are built on a base class known as [`nn.Module`](https://github.com/torch/nn/blob/master/Module.lua). Thus, in order to understand the rest of the package, we must first understand [`nn.Module`](https://github.com/torch/nn/blob/master/Module.lua). The [docs](https://github.com/torch/nn/blob/master/doc/module.md) are comprehensive but somewhat hard to parse, so we'll eschew those and just look at the code:\n",
      "\n",
      "You'll want to point your browser to the code for [`nn.Module`](https://github.com/torch/nn/blob/master/Module.lua).\n",
      "\n",
      "Now, direct your attention to the [`init`](https://github.com/torch/nn/blob/master/Module.lua#L3) method. The two important things going on here are the initialization of `self.gradInput` and `self.output`. The former holds the gradient that travels backwards through this layer (think [$\\partial f/\\partial z$](neural_nets.ipynb#Training)) while the latter holds the output. Practically, this means is that you can access these important values using `myModule.gradInput` and `myModule.output`, respectively. There are some other effects that have to deal with the `_type`, but we'll ignore that for now.\n",
      "\n",
      "Temporarily skipping over the `parameters` method, we eventually come to [`forward`](https://github.com/torch/nn/blob/master/Module.lua#L25), which just calls `updateOutput`; you generally don't want to change this and, instead, override [`updateOutput`](https://github.com/torch/nn/blob/master/Module.lua#L21).\n",
      "\n",
      "[`updateOutput`](https://github.com/torch/nn/blob/master/Module.lua#L21) is where (half of) the real work of the Module happens. You override (replace) this function with whatever computation you desire and then make `self.output` the result.\n",
      "\n",
      "Continuing on, we arrive at [`backward`](https://github.com/torch/nn/blob/master/Module.lua#L29), which is a bit like `forward` in that it simply calls some other methods: `updateGradInput` and `accGradParameters`.\n",
      "\n",
      "Try your hardest to ignore all of the intervening code and settle your gaze upon [`updateGradInput`](https://github.com/torch/nn/blob/master/Module.lua#L42). This function is the backward counterpart of `updateOutput` which takes the gradient w.r.t. the output (e.g., $\\frac{\\partial \\mathcal{L}}{\\partial o}$) and applies the chain rule (e.g., $\\frac{\\partial \\mathcal{L}}{\\partial o}\\frac{\\partial o}{\\partial f}$) to get the gradient w.r.t. the input--the output of the previous module. Naturally, this gets stored in `self.gradInput`.\n",
      "\n",
      "\"What about the parameters?\" you say. Great question, that's what happens in [`accGradParameters`](https://github.com/torch/nn/blob/master/Module.lua#L46). This function doesn't return anything and, instead, just collects the $\\partial z/\\partial W$s until we take a gradient descent step at the very end.\n",
      "\n",
      "Clear as mud, right? No worries, it should become clearer when we get to an example!\n",
      "\n",
      "#### Mulling Over a Module\n",
      "\n",
      "Let's scale up the learning with a simple Module, [`nn.Mul`](https://github.com/torch/nn/blob/master/Mul.lua), which learns to multiply the input by a number, $c$. In math parlance, $f(X) = cX$.\n",
      "\n",
      "On [line 1](https://github.com/torch/nn/blob/master/Mul.lua#L1), you can see that we're creating `nn.Mul` from a base class `nn.Module` (go figure).\n",
      "\n",
      "In [`__init`](https://github.com/torch/nn/blob/master/Mul.lua#L4) the new thing happening here is that there are two new variables: `self.weight` and `self.gradWeight` which hold the number and the accumulated gradient w.r.t. the number ($\\partial\\mathcal{L}/dc$). Since this is a `nn.Module` and it calls [`parent.__init(self)`](https://github.com/torch/nn/blob/master/Mul.lua#L4), we know that `self.output` and `self.gradInput` are initialized to empty Tensors.\n",
      "\n",
      "[`updateOutput`](https://github.com/torch/nn/blob/master/Mul.lua#L23) is reasonably straightforward: it makes some room for the output using `resize` and copies in the input (it's important to do a copy, because it needs the input later to compute the gradient!). After a quick `mul` by $c$, the module returns its output.\n",
      "\n",
      "[`updateGradInput`](https://github.com/torch/nn/blob/master/Mul.lua#L29) proceeds similarly. This function computes $\\partial f/\\partial x = c$, and applies the chain rule so that `gradInput = c*gradOutput`. Don't let the call to [`add`](https://torch7.readthedocs.io/en/latest/maths/index.html#res-torchaddres-tensor1-value-tensor2) throw you off: if you check the types (scalar, Tensor) and then look at the [docs](https://torch7.readthedocs.io/en/latest/maths/index.html#res-torchaddres-tensor1-value-tensor2) (scroll down to the first example in red), you'll find that this invocation\n",
      "\n",
      "> `x:add(value, y)` multiply-accumulates values of `y` into `x`\"\n",
      "\n",
      "Great! Now on to the final piece of the puzzle, [`accGradParameters`](https://github.com/torch/nn/blob/master/Mul.lua#L35), which just takes $\\partial f/\\partial c = X$, applies the chain rule, and adds the result into the existing `gradWeight`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mul42 = nn.Mul()\n",
      "mul42.weight = torch.Tensor{42}\n",
      "print(mul42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "nn.Mul\n",
        "{\n",
        "  weight : DoubleTensor - size: 1\n",
        "  _type : torch.DoubleTensor\n",
        "  output : DoubleTensor - empty\n",
        "  gradInput : DoubleTensor - empty\n",
        "  gradWeight : DoubleTensor - size: 1\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input = torch.range(1, 3)\n",
      "mul42:forward(input)\n",
      "print(mul42.output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "  42\n",
        "  84\n",
        " 126\n",
        "[torch.DoubleTensor of size 3]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradOutput = torch.ones(3)\n",
      "mul42:backward(input, gradOutput)\n",
      "print(mul42.gradInput)\n",
      "print(mul42.gradWeight) -- 1 + 2 + 3 = input:sum()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        " 42\n",
        " 42\n",
        " 42\n",
        "[torch.DoubleTensor of size 3]\n",
        "\n",
        " 6\n",
        "[torch.DoubleTensor of size 1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### So Many Modules... I Can Hardly Contain My Excitement!\n",
      "\n",
      "Whereas a vanilla Module is great when you have an input and want to create a new output, most often, you'll want to string other Modules together. For this, you need a [`Container`](https://github.com/torch/nn/blob/master/Container.lua). A [`Container`](https://github.com/torch/nn/blob/master/Container.lua) extends Module to provide, in addition to our friend like `self.output`, `self.gradInput`, `updateOutput()`, and `updateGradInput()`, the `self.modules` property and methods like [`add`](https://github.com/torch/nn/blob/master/Container.lua#L10) and the recursive [`applyToModules`](https://github.com/torch/nn/blob/master/Container.lua#L10).\n",
      "\n",
      "By far, the most important part of being a Container is that its contained Modules are in the `self.modules` table. Otherwise, the rest of the Container functions won't know to use them!\n",
      "\n",
      "#### It's as Easy as 1, 2, 3\n",
      "\n",
      "By far, the most ubiquitous Module is [`nn.Sequential`](https://github.com/torch/nn/blob/master/Sequential.lua), which [takes an input and feeds it--sequentially--through the network](https://github.com/torch/nn/blob/master/Sequential.lua#L41). As this, very much, follows the paradigm of \"layers,\" you'll not be surprised that the wrapper of most of your networks will be `nn.Sequential`.\n",
      "\n",
      "Here's a quick example that looks a lot like our Perceptron from earlier:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = nn.Sequential()\n",
      "model:add(nn.Linear(3, 5))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5, 5))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5, 1))\n",
      "print(tostring(model)) -- the tostring is only needed in iTorch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "nn.Sequential {\n",
        "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]\n",
        "  (1): nn.Linear(3 -> 5)\n",
        "  (2): nn.ReLU\n",
        "  (3): nn.Linear(5 -> 5)\n",
        "  (4): nn.ReLU\n",
        "  (5): nn.Linear(5 -> 1)\n",
        "}\t\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input = torch.rand(4, 3) -- minibatch of 4 samples with 3 features each\n",
      "model:forward(input)\n",
      "for i=1,#model do\n",
      "    print(model:get(i).output)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "-0.1965 -0.6051  0.0388  0.7276 -0.1459\n",
        "-0.3223 -0.6469  0.0522  0.6468 -0.1782\n",
        "-0.5566 -0.7844  0.2429  0.8058 -0.4212\n",
        "-0.5529 -0.5965 -0.0383  0.6751 -0.3506\n",
        "[torch.DoubleTensor of size 4x5]\n",
        "\n",
        " 0.0000  0.0000  0.0388  0.7276  0.0000\n",
        " 0.0000  0.0000  0.0522  0.6468  0.0000\n",
        " 0.0000  0.0000  0.2429  0.8058  0.0000\n",
        " 0.0000  0.0000  0.0000  0.6751  0.0000\n",
        "[torch.DoubleTensor of size 4x5]\n",
        "\n",
        "-0.1390  0.1903 -0.1857  0.2307 -0.3862\n",
        "-0.1347  0.1868 -0.1570  0.2556 -0.3915\n",
        "-0.1764  0.2401 -0.2926  0.2659 -0.4469\n",
        "-0.1290  0.1779 -0.1497  0.2339 -0.3752\n",
        "[torch.DoubleTensor of size 4x5]\n",
        "\n",
        " 0.0000  0.1903  0.0000  0.2307  0.0000\n",
        " 0.0000  0.1868  0.0000  0.2556  0.0000\n",
        " 0.0000  0.2401  0.0000  0.2659  0.0000\n",
        " 0.0000  0.1779  0.0000  0.2339  0.0000\n",
        "[torch.DoubleTensor of size 4x5]\n",
        "\n",
        "-0.3710\n",
        "-0.3689\n",
        "-0.3750\n",
        "-0.3692\n",
        "[torch.DoubleTensor of size 4x1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Final Judgement\n",
      "\n",
      "So, you have a model. Cool. Is it any good? Who knows! Actually, the [`Criterion`](https://github.com/torch/nn/blob/master/Criterion.lua) does.\n",
      "\n",
      "A [`Criterion`](https://github.com/torch/nn/blob/master/Criterion.lua) is kind of like a Module in that it has  `forward` and `backward`, but is unique in that they take a second argument: `target`.\n",
      "\n",
      "As with Modules, there are a [ton](https://github.com/torch/nn/blob/master/doc/criterion.md) of different Criterions. Choosing the right Criterion is very important as this determines what the network will learn.\n",
      "\n",
      "### All together now\n",
      "\n",
      "So now we have a network that takes a vector with three elements and produces a single number. How about we train it to learn how to take the average of the three numbers?\n",
      "\n",
      "The question of the hour is of what Criterion should we use. One good choice is [`nn.MSECriterion`](https://github.com/torch/nn/blob/master/doc/criterion.md#nn.MSECriterion) which is the $\\mathcal{L}(x, y) = (x - y)^2$ we used earlier. This is sort of like asking the output to be \"close enough\" while ensuring that no value is particularly off.\n",
      "\n",
      "Here's how the network performs before any training:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "origModel = model:clone()\n",
      "origModel:reset()\n",
      "\n",
      "testData = torch.range(1, 4*3):view(4, 3)\n",
      "print(testData)\n",
      "expectedOutput = testData:mean(2)\n",
      "print(expectedOutput)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "  1   2   3\n",
        "  4   5   6\n",
        "  7   8   9\n",
        " 10  11  12\n",
        "[torch.DoubleTensor of size 4x3]\n",
        "\n",
        "  2\n",
        "  5\n",
        "  8\n",
        " 11\n",
        "[torch.DoubleTensor of size 4x1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(origModel:forward(testData))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        " 0.4441\n",
        " 0.5053\n",
        " 0.4998\n",
        " 0.5056\n",
        "[torch.DoubleTensor of size 4x1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Terrible. Absolutely terrible. Let's see if we can get it to learn something!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model:reset()\n",
      "crit = nn.AbsCriterion() -- (x - y)^2\n",
      "N = 100000 -- train for 100k iters\n",
      "for i=1,N do\n",
      "    local input = torch.Tensor(100, 3):random(10)\n",
      "    local target = input:max(2)\n",
      "    model:forward(input)\n",
      "    local loss = crit:forward(model.output, target)\n",
      "    \n",
      "    model:zeroGradParameters()\n",
      "    crit:backward(model.output, target)\n",
      "    model:backward(input, crit.gradInput)\n",
      "    model:updateParameters(0.01)\n",
      "    \n",
      "    xlua.progress(i, N)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [.......................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 0ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==>....................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s711ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======>................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 12s993ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==========>............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s765ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==============>........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s645ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=================>.....................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 9s585ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=====================>.................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 8s530ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=========================>.............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 8s44ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=============================>.........................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 7s65ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [================================>......................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 5s895ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [====================================>..................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 4s746ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [========================================>..............]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 3s757ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [============================================>..........]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 2s685ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===============================================>.......]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 1s702ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===================================================>...]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 796ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======================================================>]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b Tot: 15s452ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(model:forward(testData), expectedOutput)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "  3.0756\n",
        "  7.8454\n",
        " 10.0007\n",
        " 10.0007\n",
        "[torch.DoubleTensor of size 4x1]\n",
        "\n",
        "  2\n",
        "  5\n",
        "  8\n",
        " 11\n",
        "[torch.DoubleTensor of size 4x1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not too shabby for only being able to do sums, multiplications, and thresholding at zero!\n",
      "\n",
      "## Go Forth (and Back)\n",
      "\n",
      "You now have all of the tools you need to start classifying MNIST digits! Crazy, right?\n",
      "\n",
      "### I Want to Be the Very Best...\n",
      "\n",
      "Start by popping open the [training script](../edit/mnist/main.lua).\n",
      "\n",
      "You don't have to concern youself much with the details of it but it will help to be aware of a few things:\n",
      "\n",
      "First is that that there are several named arguments that you can change like `seed`, `nEpochs`, any of the options listed under \"Optimization options\".\n",
      "\n",
      "Additionally, on line 39, you'll see that we're using the [`nn.CrossEntropyCriteron`](https://github.com/torch/nn/blob/master/doc/criterion.md#nn.CrossEntropyCriterion) which is like the binary cross-entropy we used in the original Perceptron example but generalized to $n$ classes.\n",
      "\n",
      "Finally, unlike above where we used `updateParamters(0.01)`, this training script uses the SGD available in the powerful `optim` package which has, along with other optimizers entirely, an implementation of SGD that includes bells and whistles like weight-decay and momentum. This is configured on line 41 and is used on line 75.\n",
      "\n",
      "### I'm Ready for My Close-Up\n",
      "\n",
      "Finally, we get to write a real-life model! This model will live in [mnist/models/mlp.lua](../edit/mnist/models/mlp.lua) which is named \"mlp.lua\" because that's what you're going to write: a multi-layer perceptron!\n",
      "\n",
      "In the spirit of the max-finding model, above, you should--at the very least--put together a model that contains some [`nn.Linear`s](https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear) and some [non-linearities](https://github.com/torch/nn/blob/master/doc/transfer.md) like [`nn.ReLU`](https://github.com/torch/nn/blob/master/doc/transfer.md#relu). You are encouraged to experiment with other modules!\n",
      "\n",
      "**Important:** remember to keep tabs on your input and output dimensions! The first thing that you should notice is that the input is a $N\\times 28 \\times 28$ Tensor (where $N$ is the batch size). This is a problem if you want to feed it into a `nn.Linear` since `nn.Linear` only takes $N \\times d$ Tensors. You will need to flatten your image first using [`nn.View`](https://github.com/torch/nn/blob/master/doc/simple.md#view) (scroll down to \"Example 2\" for an... example. It's slightly different, though: our images have an additional dimension!).\n",
      "\n",
      "You can test that your model conforms to the spec by running the code below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dofile('mnist/test/mlp_io.lua')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "nn.Sequential {\n",
        "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> output]\n",
        "  (1): nn.View(784)\n",
        "  (2): nn.Linear(784 -> 1000)\n",
        "  (3): nn.ReLU\n",
        "  (4): nn.Linear(1000 -> 500)\n",
        "  (5): nn.ReLU\n",
        "  (6): nn.Linear(500 -> 100)\n",
        "  (7): nn.ReLU\n",
        "  (8): nn.Linear(100 -> 10)\n",
        "}\n",
        "{\n",
        "  gradInput : DoubleTensor - empty\n",
        "  modules : \n",
        "    {\n",
        "      1 : \n",
        "        nn.View(784)\n",
        "        {\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "gradInput : DoubleTensor - empty\n",
        "          size : LongStorage - size: 1\n",
        "          numElements : 784\n",
        "        }\n",
        "      2 : \n",
        "        nn.Linear(784 -> 1000)\n",
        "        {\n",
        "          gradBias : DoubleTensor - size: 1000\n",
        "          weight : DoubleTensor - size: 1000x784\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          bias : DoubleTensor - size: 1000\n",
        "          gradWeight : DoubleTensor - size: 1000x784\n",
        "        }\n",
        "      3 : \n",
        "        nn.ReLU\n",
        "        {\n",
        "          inplace : false\n",
        "          threshold : 0\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          val : 0\n",
        "        }\n",
        "      4 : \n",
        "        nn.Linear(1000 -> 500)\n",
        "        "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "{\n",
        "          gradBias : DoubleTensor - size: 500\n",
        "          weight : DoubleTensor - size: 500x1000\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          bias : DoubleTensor - size: 500\n",
        "          gradWeight : DoubleTensor - size: 500x1000\n",
        "        }\n",
        "      5 : \n",
        "        nn.ReLU\n",
        "        {\n",
        "          inplace : false\n",
        "          threshold : 0\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          val : 0\n",
        "        }\n",
        "      6 : \n",
        "        nn.Linear(500 -> 100)\n",
        "        {\n",
        "          gradBias : DoubleTensor - size: 100\n",
        "          weight : DoubleTensor - size: 100x500\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          bias : DoubleTensor - size: 100\n",
        "          gradWeight : DoubleTensor - size: 100x500\n",
        "        }\n",
        "      7 : \n",
        "        nn.ReLU\n",
        "        {\n",
        "          inplace : false\n",
        "          threshold : 0\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          val : 0\n",
        "        }\n",
        "      "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "8 : \n",
        "        nn.Linear(100 -> 10)\n",
        "        {\n",
        "          gradBias : DoubleTensor - size: 10\n",
        "          weight : DoubleTensor - size: 10x100\n",
        "          _type : torch.DoubleTensor\n",
        "          output : DoubleTensor - empty\n",
        "          gradInput : DoubleTensor - empty\n",
        "          bias : DoubleTensor - size: 10\n",
        "          gradWeight : DoubleTensor - size: 10x100\n",
        "        }\n",
        "    }\n",
        "  _type : torch.DoubleTensor\n",
        "  output : DoubleTensor - empty\n",
        "}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "Passed!\t\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you're ready to roll, run the following code block. Try to get the best performance you can!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainMNIST = dofile('mnist/main.lua')\n",
      "\n",
      "trainMNIST()\n",
      "-- trainMNIST({dispFreq=2, nEpochs=10, batchSize=1024, lr=0.01}) -- twiddle some hyperparameters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [.......................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 0ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [>......................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 19s679ms | Step: 42ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=>.....................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 18s483ms | Step: 41ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==>....................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 17s835ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===>...................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 17s322ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=====>.................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 16s891ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======>................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 16s363ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=======>...............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 15s934ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [========>..............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 15s505ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==========>............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 15s50ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===========>...........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s586ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [============>..........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s159ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==============>........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 13s619ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===============>.......................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 13s126ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=================>.....................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 12s658ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==================>....................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 12s208ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===================>...................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s796ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [====================>..................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s348ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======================>................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s816ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=======================>...............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s389ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=========================>.............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 9s945ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==========================>............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 9s458ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===========================>...........................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 9s13ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=============================>.........................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 8s535ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==============================>........................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 8s51ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===============================>.......................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 7s645ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [================================>......................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 7s239ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==================================>....................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 6s794ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===================================>...................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 6s359ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [====================================>..................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 5s959ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=====================================>.................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 5s518ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=======================================>...............]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 5s35ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [========================================>..............]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 4s556ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==========================================>............]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 4s111ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===========================================>...........]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 3s627ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [============================================>..........]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 3s143ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==============================================>........]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 2s702ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===============================================>.......]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 2s299ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [================================================>......]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 1s814ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==================================================>....]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 1s371ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===================================================>...]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 846ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [====================================================>..]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 403ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======================================================>]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b Tot: 18s864ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=========================>.............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 0ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======================================================>]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b Tot: 402ms | Step: 9ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "Epoch  1 | train loss: 0.290 | val loss: 0.137 | val acc: 95.86%\t\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [>......................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 0ms | Step: 0ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=>.....................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 18s548ms | Step: 41ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===>...................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 17s711ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [====>..................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 17s161ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=====>.................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 16s667ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======>................................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 16s268ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [========>..............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 15s806ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=========>.............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 15s393ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==========>............................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s931ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [============>..........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s494ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=============>.........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 14s111ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==============>........................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 13s651ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===============>.......................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 13s160ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=================>.....................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 12s703ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [==================>....................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 12s272ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===================>...................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s820ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=====================>.................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s513ms | Step: 40ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [======================>................................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 11s166ms | Step: 41ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=======================>...............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s836ms | Step: 41ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [========================>..............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s460ms | Step: 42ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [=========================>.............................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 10s222ms | Step: 42ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [===========================>...........................]                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b ETA: 9s772ms | Step: 42ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b "
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}